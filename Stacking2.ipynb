{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KNeighborsClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-038803c74c4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Initializing models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mclf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mclf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mclf3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'KNeighborsClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Initializing models\n",
    "\n",
    "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "lr = LogisticRegression()\n",
    "sclf = StackingClassifier(classifiers=[clf1, clf1, clf2, clf3], \n",
    "                          meta_classifier=lr)\n",
    "\n",
    "params = {'kneighborsclassifier-1__n_neighbors': [1, 5],\n",
    "          'kneighborsclassifier-2__n_neighbors': [1, 5],\n",
    "          'randomforestclassifier__n_estimators': [2000,3000,3500,4000],\n",
    "          'meta-logisticregression__C': [0.1, 10.0]}\n",
    "\n",
    "grid = GridSearchCV(estimator=sclf, \n",
    "                    param_grid=params, \n",
    "                    cv=5,\n",
    "                    refit=True,n_jobs=-1)\n",
    "\n",
    "grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data[:, 1:3], iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['grid']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn import pipeline\n",
    "sklearn.__version__\n",
    "# Import SciKit Learn functions\n",
    "from sklearn.metrics import roc_curve, auc , roc_auc_score, confusion_matrix, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import grid_search\n",
    "from sklearn import tree\n",
    "%pylab inline\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "try:\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    from sklearn.pipeline import make_pipeline\n",
    "except ImportError:\n",
    "    # use backports for sklearn 1.4\n",
    "    # available from https://s3.amazonaws.com/datarobotblog/notebooks/sklearn_backports.py\n",
    "    from sklearn_backports import PolynomialFeatures\n",
    "    from sklearn_backports import make_pipeline\n",
    "\n",
    "# ignore DeprecateWarnings by sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn.cross_validation\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "#because dataset is skewed we can try out logistic regression with balanced weights\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(df_train.SeriousDlqin2yrs))\n",
    "    plt.xticks(tick_marks, df_train.SeriousDlqin2yrs, rotation=45)\n",
    "    plt.yticks(tick_marks, df_train.SeriousDlqin2yrs)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('train_ireg_amd_dmd.csv')\n",
    "df_test=pd.read_csv('test_ireg_amd_dmd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Currently getting subset of data and just wrangling around and trying\n",
    "\n",
    "Y_train=np.array(df_train.SeriousDlqin2yrs)\n",
    "#features = ['RevolvingUtilizationOfUnsecuredLines', 'DebtRatio',\n",
    "#            'MonthlyIncome', 'age', 'NumberOfTimes90DaysLate']\n",
    "features=['RevolvingUtilizationOfUnsecuredLines','age','NumberOfTime30-59DaysPastDueNotWorse','DebtRatio','MonthlyIncome','NumberOfOpenCreditLinesAndLoans','NumberOfTimes90DaysLate','NumberRealEstateLoansOrLines','NumberOfTime60-89DaysPastDueNotWorse','NumberOfDependents']\n",
    "X_train=np.array(df_train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X_train, Y_train, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = {'objective':'binary:logistic','booster':'gbtree','eta':0.01, # 0.06, #0.01,0.005\n",
    "        'max_depth':20, #changed from default of 4,6,8,10,15,20\n",
    "        'subsample':0.5, #(.5,0.7,1)\n",
    "        'colsample_bytree':0.5, #(.5,0.7,1)\n",
    "        'min_child_weight':44.8833}\n",
    "\n",
    "param['nthread'] = 4\n",
    "param['eval_metric'] = 'auc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_all=xgb.DMatrix(X_train,Y_train)\n",
    "clf_best=xgb.train(param,train_all,num_boost_round=420,maximize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='auto', criterion='gini',\n",
       "            max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=2000, n_jobs=-1, oob_score=True,\n",
       "            random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "import numpy as np\n",
    "# Initializing models\n",
    "\n",
    "\n",
    "#clf1 = KNeighborsClassifier(n_neighbors=1,n_jobs=-1)\n",
    "clf2 = RandomForestClassifier(bootstrap=True, class_weight='auto', criterion='gini',\n",
    "            max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=-1,\n",
    "            oob_score=True, random_state=None, verbose=0, warm_start=False)\n",
    "clf4=GradientBoostingClassifier(loss='deviance', max_features = 'auto',learning_rate=0.01,n_estimators=2500,max_depth=3)\n",
    "\n",
    "\n",
    "clf2.fit(X_train,Y_train)\n",
    "\n",
    "#lr=GradientBoostingClassifier(verbose=1)\n",
    "\n",
    "#sclf = StackingClassifier(classifiers=[clf2,clf4], \n",
    "#                         meta_classifier=clf2,verbose=1,use_probas=True)\n",
    "\n",
    "#params = {'random_forst': [1,2000],\n",
    "#          'gradient_boosting': [100,2500],\n",
    "#          'meta-gradient_boosting': [0.1, 10.0]}\n",
    "\n",
    "\n",
    "\n",
    "#grid = GridSearchCV(estimator=sclf, \n",
    "           #         param_grid=params, \n",
    "           #        cv=5,\n",
    "            #        refit=True)\n",
    "\n",
    "#grid.fit(X_train, Y_train)\n",
    "\n",
    "#sclf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC score on model with depth   0.847116214436\n"
     ]
    }
   ],
   "source": [
    "prob=clf2.predict_proba(X_validation)\n",
    "auc_score=roc_auc_score(Y_validation,prob[:,1])\n",
    "print \"ROC score on model with depth  \",roc_auc_score(Y_validation,prob[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "roc_auc_score(Y_validation,pred_logisticmodel[:,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
